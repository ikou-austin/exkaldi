{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will make a HCLG decode graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = os.path.join(\"..\",\"examplesdata\",\"librispeech_dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare lexicons (generated in 3_prepare_lexicons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.decode.graph.LexiconBank at 0x7fc0e5810a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the traing of HMM and decision tree, we also have high-level API to make HCLG graph. But firstly we introduce how to build HCLG graph with exkaldi toolkit in detail.\n",
    "\n",
    "### Make HCLG in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make G file from ARPA language model (generated in 4_train_and_query_language_model).\n",
    "\n",
    "This is a 3-grams LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"graph\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/graph/G.fst'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arpaFile = os.path.join(dataDir, \"exp\", \"3-gram.arpa\")\n",
    "Gfile = os.path.join(outDir, \"G.fst\")\n",
    "\n",
    "exkaldi.decode.graph.make_G(lexicons, arpaFile, outFile=Gfile, order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compose __L.fst__ and __G.fst__ to __LG.fst__. \n",
    "\n",
    "__L.fst__ file has been generated before (in 3_prepare_lexicons), use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/graph/LG.fst'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L_disambig.fst\")\n",
    "LGfile = os.path.join(outDir, \"LG.fst\")\n",
    "\n",
    "exkaldi.decode.graph.compose_LG(Lfile, Gfile, outFile=LGfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compose __LG__ and context information to __CLG.fst__. \n",
    "\n",
    "__tree__ will be used here. and __ilabel__ info will also be generated in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/graph/CLG.ilabels'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeFile = os.path.join(dataDir, \"exp\", \"train_tree\", \"tree\")\n",
    "CLGfile = os.path.join(outDir, \"CLG.fst\")\n",
    "\n",
    "_, ilabelFile = exkaldi.decode.graph.compose_CLG(lexicons, treeFile, LGfile, outFile=CLGfile)\n",
    "\n",
    "ilabelFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, compose all infos to final __HCLG.fst__ graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/graph/HCLG.fst'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")\n",
    "HCLGFile = os.path.join(outDir, \"HCLG.fst\")\n",
    "\n",
    "exkaldi.decode.graph.compose_HCLG(hmmFile, treeFile, CLGfile, ilabelFile, outFile=HCLGFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make HCLG with high-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(Gfile)\n",
    "os.remove(LGfile)\n",
    "os.remove(CLGfile)\n",
    "os.remove(ilabelFile)\n",
    "os.remove(HCLGFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip making L. Use: ../examplesdata/librispeech_light/exp/L_disambig.fst.\n",
      "Make G done: /misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_light/exp/graph/G.fst.\n",
      "Compose LG done: /misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_light/exp/graph/LG.fst.\n",
      "Compose CLG done: /misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_light/exp/graph/CLG.fst.\n",
      "Ilabel info: /misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_light/exp/graph/CLG.ilabels.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_light/exp/graph/HCLG.fst'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"graph\")\n",
    "\n",
    "exkaldi.decode.graph.make_graph(lexicons, arpaFile, hmmFile, treeFile, tempDir=tmpDir, useLFile=Lfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified \"useLFile\" to use the L file generated before. If you don't want this, specify \"useLFile\" None, and other parameters, such as \"useDisambigLexicons\" and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
