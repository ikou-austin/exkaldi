{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will decode based on HMM-GMM model and WFST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = \"librispeech_dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a word-id table. We use the lexicons generated in early step directly. So load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.decode.graph.LexiconBank at 0x7f631d610400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lexicons, call \"words\" to get the word-id table if you want decode in words level. Or call \"phones\" to get the phone-ID table when decoding in phone level. But both them will return the Exkaldi ListTable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exkaldi.core.achivements.ListTable"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lexicons(\"words\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the acoustic feature for test. We compute the feature as same as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.achivements.BytesFeature at 0x7f638cc9aef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scpFile = os.path.join(dataDir, \"test\", \"wav.scp\")\n",
    "utt2spkFile = os.path.join(dataDir, \"test\", \"utt2spk\")\n",
    "spk2uttFile = os.path.join(dataDir, \"test\", \"spk2utt\")\n",
    "\n",
    "feat = exkaldi.compute_mfcc(scpFile, name=\"mfcc\")\n",
    "cmvn = exkaldi.compute_cmvn_stats(feat, spk2utt=spk2uttFile, name=\"cmvn\")\n",
    "feat = exkaldi.use_cmvn(feat, cmvn, utt2spk=utt2spkFile)\n",
    "\n",
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/test_mfcc.ark'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"test_mfcc.ark\")\n",
    "\n",
    "feat.save(featFile, outScpFile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the HMM-GMM model and WFST decoding graph. They have been generated in early steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCLGFile = os.path.join(dataDir, \"exp\", \"graph\", \"HCLG.fst\")\n",
    "\n",
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then decode. You can set some decoding parameters such as __beam__, __acwt__ and so on. Here we only use default configures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm-latgen-faster --allow-partial=true --min-active=200 --max-active=7000 --max_mem=50000000 --beam=10 --lattice-beam=8 --acoustic-scale=1 --word-symbol-table=/tmp/tmpippec5t3_words.txt librispeech_dummy/exp/train_delta/final.mdl librispeech_dummy/exp/graph/HCLG.fst ark:- ark:- \n",
      "ERROR (gmm-latgen-faster[5.5.372~1-acff3]:LogLikelihoodZeroBased():decodable-am-diag-gmm.cc:50) Dim mismatch: data dim = 13 vs. model dim = 117\n",
      "\n",
      "[ Stack-Trace: ]\n",
      "kaldi::MessageLogger::LogMessage() const\n",
      "kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&)\n",
      "kaldi::DecodableAmDiagGmmUnmapped::LogLikelihoodZeroBased(int, int)\n",
      "kaldi::DecodableAmDiagGmmScaled::LogLikelihood(int, int)\n",
      "kaldi::LatticeFasterDecoderTpl<fst::Fst<fst::ArcTpl<fst::TropicalWeightTpl<float> > >, kaldi::decoder::StdToken>::ProcessEmitting(kaldi::DecodableInterface*)\n",
      "kaldi::LatticeFasterDecoderTpl<fst::Fst<fst::ArcTpl<fst::TropicalWeightTpl<float> > >, kaldi::decoder::StdToken>::Decode(kaldi::DecodableInterface*)\n",
      "bool kaldi::DecodeUtteranceLatticeFaster<fst::Fst<fst::ArcTpl<fst::TropicalWeightTpl<float> > > >(kaldi::LatticeFasterDecoderTpl<fst::Fst<fst::ArcTpl<fst::TropicalWeightTpl<float> > >, kaldi::decoder::StdToken>&, kaldi::DecodableInterface&, kaldi::TransitionModel const&, fst::SymbolTable const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, double, bool, bool, kaldi::TableWriter<kaldi::BasicVectorHolder<int> >*, kaldi::TableWriter<kaldi::BasicVectorHolder<int> >*, kaldi::TableWriter<kaldi::CompactLatticeHolder>*, kaldi::TableWriter<kaldi::LatticeHolder>*, double*)\n",
      "main\n",
      "__libc_start_main\n",
      "_start\n",
      "\n",
      "WARNING (gmm-latgen-faster[5.5.372~1-acff3]:~HashList():util/hash-list-inl.h:117) Possible memory leak: 1022 != 1024: you might have forgotten to call Delete on some Elems\n",
      "kaldi::KaldiFatalError\n"
     ]
    },
    {
     "ename": "KaldiProcessError",
     "evalue": "Failed to generate lattice.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKaldiProcessError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-13017cebd294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexkaldi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwfst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmm_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhmmFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHCLGFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordSymbolTable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlexicons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/home/usr18/wangyu/.virtualenvs/tfenv/lib/python3.6/site-packages/exkaldi/decode/wfst.py\u001b[0m in \u001b[0;36mgmm_decode\u001b[0;34m(feat, hmm, HCLGFile, wordSymbolTable, beam, latBeam, acwt, minActive, maxActive, maxMem, config, maxThreads)\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcod\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mKaldiProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to generate lattice.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                         \u001b[0mnewName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"lat({feat.name})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKaldiProcessError\u001b[0m: Failed to generate lattice."
     ]
    }
   ],
   "source": [
    "lat = exkaldi.decode.wfst.gmm_decode(feat, hmmFile, HCLGFile, wordSymbolTable=lexicons(\"words\"))\n",
    "\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___lat___ is an exkaldi __Lattice__ object. We will introduce it's property in detail in next step. Now, save it to file with kaldi format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"decode_test\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latFile = os.path.join(outDir \"test.lat\")\n",
    "\n",
    "lat.save(latFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
