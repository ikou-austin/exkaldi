{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will train the triphone HMM-GMM up to train_delta step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = os.path.join(\"..\",\"examplesdata\",\"librispeech_dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, make a triphone model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.hmm.hmm.TriphoneHMM at 0x7f778c5ec0f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = exkaldi.hmm.TriphoneHMM()\n",
    "\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___model1___ is unavaliable now. We have to initialize its data. \n",
    "\n",
    "We will use thses files which have been generated in early steps.\n",
    "\n",
    "___tree___ and ___treeStats___ : generated in 6_train_decision_tree\n",
    "\n",
    "___topo___:  generated in 5_train_mono_HMM-GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeFile = os.path.join(dataDir, \"exp\", \"train_tree\", \"tree\")\n",
    "treeStatsFile = os.path.join(dataDir, \"exp\", \"train_tree\", \"treeStats.acc\")\n",
    "topoFile = os.path.join(dataDir, \"exp\", \"topo\")\n",
    "numgauss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(phones=69, pdfs=784, transitionIds=1854, transitionStates=919, dimension=117, gaussians=1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.initialize(tree=treeFile, treeStatsFile=treeStatsFile, topoFile=topoFile, numgauss=numgauss)\n",
    "\n",
    "model1.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training steps of triphone HMM are almost the same as monophone HMM except that we don't use equally aligning at the first time.\n",
    "\n",
    "We will introduce the traing step in a nutshell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training in deltail\n",
    "\n",
    "At the first step, we must generate the new alignment data in the first step. You can convert the lastest alignment data generated by monophone model to a new alignment data corresponding to triphone. Use the generated alignment and final monophone model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliFile = os.path.join(dataDir, \"exp\", \"train_mono\", \"final.ali\")\n",
    "monoFile= os.path.join(dataDir, \"exp\", \"train_mono\", \"final.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.achivements.BytesAlignmentTrans at 0x7f777d97a1d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newAli = exkaldi.hmm.convert_alignment(aliFile, monoFile, model1, treeFile)\n",
    "\n",
    "newAli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another way, align feature again directly with new triphone model. In the next steps, we will review the steps to train a HMM-GMM model and use it to align acoustic feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del newAli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a lexicons (generated in 3_prepare_lexicons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.decode.graph.LexiconBank at 0x7f777d97a128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare int-format transcription (generated in 5_train_mono_HMM-GMM )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': '201 875 800 1004 744 653 1239 800 1004 744 725 671 1395 1268 96 751 1064 328 348 648 4 724 588 501 1416 36 53 687 367 53 1314 177 4 168'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intTransFile = os.path.join(dataDir, \"exp\", \"text.int\")\n",
    "\n",
    "trans = exkaldi.load_trans(intTransFile)\n",
    "\n",
    "trans.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare L.fst file (generated in 3_prepare_lexicons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L_disambig.fst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare feature (generated in 2_feature_processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.achivements.BytesFeature at 0x7f777d773f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"mfcc.ark\")\n",
    "\n",
    "feat = exkaldi.load_feat(featFile)\n",
    "\n",
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compile new train graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_delta\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/train_delta/train_graph'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGraphFile = os.path.join(outDir, \"train_graph\")\n",
    "\n",
    "model1.compile_train_graph(tree=treeFile, transcription=trans, LFile=Lfile, outFile=trainGraphFile, lexicons=lexicons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Align acoustic feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.achivements.BytesAlignmentTrans at 0x7f777d4b3208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = model1.align(feat, trainGraphFile, lexicons=lexicons)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Accumulate statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/train_delta/stats.acc'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsFile = os.path.join(outDir, \"stats.acc\")\n",
    "\n",
    "model1.accumulate_stats(feat=feat, alignment=ali, outFile=statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Update HMM-GMM parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(phones=69, pdfs=784, transitionIds=1854, transitionStates=919, dimension=117, gaussians=1100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetGaussians = 1100\n",
    "\n",
    "model1.update(statsFile, targetGaussians)\n",
    "\n",
    "model1.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training in high-level\n",
    "\n",
    "In this step, we will introduce how to training the triphone in directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model1\n",
    "del ali\n",
    "del trans\n",
    "\n",
    "os.remove(trainGraphFile)\n",
    "os.remove(statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some file paths or objects defined above will be used here. \n",
    "\n",
    "Firstly, initialize model. Give lexicons as a optional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(phones=69, pdfs=784, transitionIds=1854, transitionStates=919, dimension=117, gaussians=1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = exkaldi.hmm.TriphoneHMM(lexicons=lexicons)\n",
    "\n",
    "model1.initialize(tree=treeFile, treeStatsFile=treeStatsFile, topoFile=topoFile, numgauss=numgauss)\n",
    "\n",
    "model1.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train triphone model.\n",
      "Start Time: 2020/06/02-12:17:46\n",
      "Convert transcription to int value format.\n",
      "Compiling training graph.\n",
      "\n",
      "Iter 1\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 2\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 3\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 4\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 5\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 6\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 7\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 8\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 9\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 10\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Align last time with final model.\n",
      "\n",
      "Done to train the triphone model.\n",
      "Saved Final Model: ../examplesdata/librispeech_dummy/exp/train_delta/final.mdl\n",
      "Saved Alignment Model: ../examplesdata/librispeech_dummy/exp/train_delta/final.ali\n",
      "End Time: 20200602-121831\n"
     ]
    }
   ],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_delta\")\n",
    "transFile = os.path.join(dataDir, \"train\", \"text\")\n",
    "\n",
    "model1.train(feat=feat, transcription=transFile, LFile=Lfile, tree=treeFile, tempDir=outDir, \n",
    "             num_iters=10, max_iter_inc=8, totgauss=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model and alignment have been saved in file automatically. Look the final model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(phones=69, pdfs=784, transitionIds=1854, transitionStates=919, dimension=117, gaussians=1565)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
