{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will further process the Kaldi decoding lattice and score the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = os.path.join(\"..\",\"examplesdata\",\"librispeech_dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the lattice file (generated in 09_decode_back_HMM-GMM_and_WFST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.decode.wfst.Lattice at 0x7ffa8cd7e748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latFile = os.path.join(dataDir, \"exp\", \"decode_test\", \"test.lat\")\n",
    "\n",
    "lat = exkaldi.decode.wfst.load_lat(latFile)\n",
    "\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be simple and straightforward, we get the 1-best result from lattice. Word-id table and HMM model are necessary.\n",
    "\n",
    "Word-id table can be words.txt file (If decoded in word level) or phones.txt file (If decoded in phone level) or Exkaldi ListTable object. \n",
    "Ideally, LexiconBank object is also avaliable because you can get both \"words\" and \"phones\" from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsFile = os.path.join(dataDir, \"exp\", \"words.txt\")\n",
    "\n",
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': '182 790 718 908 670 595 1120 718 908 670 1155 780 605 1259 1146 89 676 965 132 314 584 4 653 529 449 1279 35 50 619 329 50 1187 161 4 153'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = lat.get_1best(wordSymbolTable=wordsFile, hmm=hmmFile, lmwt=1, acwt=0.5)\n",
    "\n",
    "result.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___result___ is a exkaldi __Transcription__ object (a subclass of Python dict).\n",
    "\n",
    "The decoding result is int-ID format. If you want it by text-format, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': 'CHAPTER ONE MISSUS RACHEL LYNDE ITS SURPRISED MISSUS RACHEL LYNDE THEY OF JUST WHERE THE AVONLEA MAIN ROAD BIT DOWN INTO A LITTLE HOLLOW FRINGED WITH ALDERS AN LADIES EARDROPS AN TRAVERSED BY A BROOK'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textResult = exkaldi.hmm.transcription_from_int(result, wordsFile)\n",
    "\n",
    "textResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for convenience, we restorage lexicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del textResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transform transcription by using the __Transcription__'s own method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': 'CHAPTER ONE MISSUS RACHEL LYNDE ITS SURPRISED MISSUS RACHEL LYNDE THEY OF JUST WHERE THE AVONLEA MAIN ROAD BIT DOWN INTO A LITTLE HOLLOW FRINGED WITH ALDERS AN LADIES EARDROPS AN TRAVERSED BY A BROOK'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id = lexicons(\"words\")\n",
    "oovID = word2id[lexicons(\"oov\")]\n",
    "id2word = word2id.reverse()\n",
    "\n",
    "textResult = result.convert(id2word, oovID)\n",
    "\n",
    "textResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can score the decoding result. Typically, you can compute the WER(word err rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(WER=35.34, words=3707, insErr=572, delErr=16, subErr=722, SER=99.0, sentences=99, wrongSentences=100, missedSentences=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refFile = os.path.join(dataDir, \"test\", \"text\")\n",
    "\n",
    "score = exkaldi.decode.score.wer(ref=refFile, hyp=textResult, mode=\"present\")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or some times, compute the edit distance score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(editDistance=2537, words=16504, SER=0.99, sentences=100, wrongSentences=99, missedSentences=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = exkaldi.decode.score.edit_distance(ref=refFile, hyp=textResult, mode=\"present\")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compute the accuracy of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8462796897721765"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - score.editDistance/score.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support further process the lattice, for example, to add penalty or to scale it.\n",
    "\n",
    "Here is a example to config different language model weight(LMWT) and penalty. (In Instead of text-format result, we use int-format reference file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refInt = exkaldi.hmm.transcription_to_int(refFile, lexicons(\"words\"), unkSymbol=lexicons(\"oov\"))\n",
    "refIntFile = os.path.join(dataDir, \"exp\", \"decode_test\", \"text.int\")\n",
    "refInt.save(refIntFile)\n",
    "\n",
    "refInt.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty 0.0, LMWT 10: WER 35.01\n",
      "Penalty 0.0, LMWT 11: WER 35.01\n",
      "Penalty 0.0, LMWT 12: WER 35.01\n",
      "Penalty 0.0, LMWT 13: WER 35.01\n",
      "Penalty 0.0, LMWT 14: WER 35.01\n",
      "Penalty 0.5, LMWT 10: WER 35.01\n",
      "Penalty 0.5, LMWT 11: WER 35.01\n",
      "Penalty 0.5, LMWT 12: WER 35.01\n",
      "Penalty 0.5, LMWT 13: WER 35.01\n",
      "Penalty 0.5, LMWT 14: WER 35.01\n",
      "Penalty 1.0, LMWT 10: WER 34.99\n",
      "Penalty 1.0, LMWT 11: WER 34.99\n",
      "Penalty 1.0, LMWT 12: WER 34.99\n",
      "Penalty 1.0, LMWT 13: WER 34.99\n",
      "Penalty 1.0, LMWT 14: WER 34.99\n"
     ]
    }
   ],
   "source": [
    "for penalty in [0., 0.5, 1.0]:\n",
    "    for LMWT in range(10, 15):\n",
    "        \n",
    "        newLat = lat.add_penalty(penalty)\n",
    "        result = newLat.get_1best(lexicons(\"words\"), hmmFile, lmwt=LMWT, acwt=0.5)\n",
    "\n",
    "        score = exkaldi.decode.score.wer(ref=refInt, hyp=result, mode=\"present\")\n",
    "        \n",
    "        print(f\"Penalty {penalty}, LMWT {LMWT}: WER {score.WER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lattice, you can get the phone-level result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': '<SIL> CH AE1 P T ER0 W AH1 N <SIL> M IH1 S IH0 Z R EY1 CH AH0 L L IH1 N D <SIL> IH0 T S S AH0 P R AY1 Z D <SIL> M IH1 S IH0 Z R EY1 CH AH0 L L IH1 N D <SIL> DH EY1 AH0 V <SIL> JH AH1 S T W EH1 R DH IY0 <SIL> AE1 V AH0 N L IY2 M EY1 N R OW1 D <SIL> B IH1 T <SIL> D AW1 N IH1 N T UW0 AH0 L IH1 T AH0 L HH AA1 L OW0 <SIL> F R IH1 N JH D W IH1 DH AO1 L D ER0 Z AH0 N L EY1 D IY0 Z IH1 R D R AA2 P S AH0 N T R AH0 V ER1 S T B AY1 AH0 B R UH1 K <SIL>'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneResult = lat.get_1best(lexicons(\"phones\"), hmmFile, lmwt=1, acwt=0.5, phoneLevel=True)\n",
    "\n",
    "phoneResult = exkaldi.hmm.transcription_from_int(phoneResult, lexicons(\"phones\"))\n",
    "\n",
    "phoneResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lattice, N-Best results can also be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-best <class 'exkaldi.core.achivements.Transcription'>\n",
      "2-best <class 'exkaldi.core.achivements.Transcription'>\n",
      "3-best <class 'exkaldi.core.achivements.Transcription'>\n"
     ]
    }
   ],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        wordSymbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=False,\n",
    "                )\n",
    "\n",
    "for re in result:\n",
    "    print(re.name, type(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___phoneResult___ is a list of N-bests __Transcription__ objects. If ___requireCost___ is True, return the LM score and AM score sumultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-best <class 'exkaldi.core.achivements.Transcription'>\n",
      "2-best <class 'exkaldi.core.achivements.Transcription'>\n",
      "3-best <class 'exkaldi.core.achivements.Transcription'>\n",
      "AM-1-best <class 'exkaldi.core.achivements.Cost'>\n",
      "AM-2-best <class 'exkaldi.core.achivements.Cost'>\n",
      "AM-3-best <class 'exkaldi.core.achivements.Cost'>\n",
      "LM-1-best <class 'exkaldi.core.achivements.Cost'>\n",
      "LM-2-best <class 'exkaldi.core.achivements.Cost'>\n",
      "LM-3-best <class 'exkaldi.core.achivements.Cost'>\n"
     ]
    }
   ],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        wordSymbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=True,\n",
    "                )\n",
    "\n",
    "for re in result[0]:\n",
    "    print(re.name, type(re))\n",
    "    \n",
    "for re in result[1]:\n",
    "    print(re.name, type(re))\n",
    "\n",
    "for re in result[2]:\n",
    "    print(re.name, type(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And importantly, Alignment can be returned to support discriminative training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-best <class 'exkaldi.core.achivements.NumpyAlignmentTrans'>\n",
      "2-best <class 'exkaldi.core.achivements.NumpyAlignmentTrans'>\n",
      "3-best <class 'exkaldi.core.achivements.NumpyAlignmentTrans'>\n"
     ]
    }
   ],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        wordSymbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=False,\n",
    "                        requireAli=True,\n",
    "                )\n",
    "\n",
    "for re in result[1]:\n",
    "    print(re.name, type(re))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
