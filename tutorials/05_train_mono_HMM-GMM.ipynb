{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will train a monophone HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = os.path.join(\"..\",\"examplesdata\",\"librispeech_dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, prepare lexicons. We have generated and saved a LexiconBank object in file already (3_prepare_lexicons). So restorage it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.decode.graph.LexiconBank at 0x7f0685966a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to  the HMM-GMM toponology file and acoustic feature data to initialize a monophone HMM-GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/topo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topoFile = os.path.join(dataDir, \"exp\", \"topo\")\n",
    "\n",
    "exkaldi.hmm.make_toponology(lexicons, outFile=topoFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In early step (2_feature_processing), we have made a mfcc feature, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.achivements.BytesFeature at 0x7f0685853f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"mfcc.ark\")\n",
    "\n",
    "feat = exkaldi.load_feat(featFile, name=\"mfcc\")\n",
    "\n",
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.hmm.hmm.MonophoneHMM at 0x7f0685853c88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = exkaldi.hmm.MonophoneHMM(lexicons=lexicons, name=\"mono\")\n",
    "\n",
    "model0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___model0___ is an Exkaldi __MonophoneHMM__ object. Exkaldi have monophone HMM-GMM and triphone HMM-GMM achivements. We will introduce the later in next tutorial steps.\n",
    "\n",
    "Now, this model is void and unavaliable. We must initialize it's archtecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(phones=69, pdfs=211, transitionIds=438, transitionStates=211, dimension=117, gaussians=211)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.initialize(feat=feat, topoFile=topoFile)\n",
    "\n",
    "model0.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are about to train this model. We provide a high-level API, __model0.train(...)__ to train this model in a nutshell, but we still introduce the basic training step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train HMM-GMM in detail\n",
    "\n",
    "#### 1. Prepare the int-ID format transcription.\n",
    "\n",
    "We actually use the transcription with int-ID format, so we convert text format to int-ID format firstly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exkaldi.core.achivements.Transcription"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transFile = os.path.join(dataDir, \"train\", \"text\")\n",
    "oov = lexicons(\"oov\")\n",
    "\n",
    "trans = exkaldi.hmm.transcription_to_int(transFile, lexicons, oov)\n",
    "\n",
    "type(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___trans___ is an exkaldi __Transcription__ object, which is designed to hold the transcription. We save the int-format transcription for further using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/text.int'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intTransFile = os.path.join(dataDir, \"exp\", \"text.int\")\n",
    "\n",
    "trans.save(intTransFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look the transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': '201 875 800 1004 744 653 1239 800 1004 744 725 671 1395 1268 96 751 1064 328 348 648 4 724 588 501 1416 36 53 687 367 53 1314 177 4 168'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compile the train graph.\n",
    "\n",
    "Compile the train graph. Here, L.fst file is necessary. In early step (3_prepare_lexicons), we have generated one, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L_disambig.fst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though decision tree is actually useless when traing monophone HMM-GMM, Kaldi still need it. \n",
    "\n",
    "When the monophone HMM is initialized, a temp tree is generated automatically. Use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.hmm.hmm.DecisionTree at 0x7f06f4d18c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = model0.tree\n",
    "\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___tree___ is an exkaldi DecisionTree object. In next step, we will introduce how to build a normal decision tree. But now, skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_mono\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/train_mono/train_graph'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGraphFile = os.path.join(outDir, \"train_graph\")\n",
    "\n",
    "model0.compile_train_graph(tree=tree, transcription=trans, LFile=Lfile, outFile=trainGraphFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Align acoustic feature averagely in order to start the first train step.\n",
    "\n",
    "Kaldi align feature equally in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.achivements.BytesAlignmentTrans at 0x7f06f4c8bcf8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = model0.align_equally(feat, trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ali___ is an exkaldi BytesAlignmentTrans object.\n",
    "\n",
    "You can covert it to numpy format to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': array([  2,   1,   1, ..., 279, 282, 281], dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali.subset(nHead=1).to_numpy(aliType=\"transitionID\", hmm=model0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use alignment to accumulate the statistics in order to update the parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/misc/Work19/wangyu/exkaldi-1.0/examplesdata/librispeech_dummy/exp/train_mono/stats.acc'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsFile = os.path.join(outDir, \"stats.acc\")\n",
    "\n",
    "model0.accumulate_stats(feat=feat, alignment=ali, outFile=statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Use these statistics to update model parameters.\n",
    "\n",
    "This step can increase the numbers of gaussians. We try to use 10 more gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(phones=69, pdfs=211, transitionIds=438, transitionStates=211, dimension=117, gaussians=221)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetGaussians = model0.info.gaussians + 10\n",
    "\n",
    "model0.update(statsFile, numgauss=targetGaussians)\n",
    "\n",
    "model0.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next training step, use Viterbi aligning to instead of average aligning.\n",
    "\n",
    "#### 6. Align acoustic feature with Vertibi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.achivements.BytesAlignmentTrans at 0x7f06f4d9be10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = model0.align(feat=feat, trainGraphFile=trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': array([146, 148, 150, ..., 277, 280, 282], dtype=int32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali.subset(nHead=1).to_numpy(aliType=\"transitionID\", hmm=model0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we have a high-level API to train the model.\n",
    "\n",
    "### Train HMM-GMM with high-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(trainGraphFile)\n",
    "os.remove(statsFile)\n",
    "del ali\n",
    "del trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to train 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train mono model.\n",
      "Start Time: 2020/06/02-11:50:59\n",
      "Convert transcription to int value format.\n",
      "Compiling training graph.\n",
      "\n",
      "Iter 0\n",
      "Aligning data equally >> Accumulate GMM statistics >> Update GMM parameters\n",
      "\n",
      "Iter 1\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 2\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 3\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 4\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 5\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 6\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 7\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 8\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 9\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Iter 10\n",
      "Aligning data >> Accumulate GMM statistics >> Update GMM parameter\n",
      "\n",
      "Align last time with final model.\n",
      "\n",
      "Done to train the monophone model.\n",
      "Saved Final Model: ../examplesdata/librispeech_dummy/exp/train_mono/final.mdl\n",
      "Saved Alignment Model: ../examplesdata/librispeech_dummy/exp/train_mono/final.ali\n",
      "End Time: 20200602-115205\n"
     ]
    }
   ],
   "source": [
    "model0.train(feat, transFile, Lfile, tempDir=outDir, num_iters=10, max_iter_inc=8, totgauss=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(phones=69, pdfs=211, transitionIds=438, transitionStates=211, dimension=117, gaussians=527)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model and alignment are saved in files automatically. You can save them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFile = os.path.join(outDir, \"0.mdl\")\n",
    "#model0.save(modelFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
