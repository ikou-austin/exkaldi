{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will train a monophone HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = \"librispeech_dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, prepare lexicons. We have generated and saved a LexiconBank object in file already (3_prepare_lexicons). So restorage it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to  the HMM-GMM toponology file and acoustic feature data to initialize a monophone HMM-GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topoFile = os.path.join(dataDir, \"exp\", \"topo\")\n",
    "\n",
    "exkaldi.hmm.make_toponology(lexicons, outFile=topoFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In early step (2_feature_processing), we have made a mfcc feature, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"mfcc.ark\")\n",
    "\n",
    "feat = exkaldi.load_feat(featFile, name=\"mfcc\")\n",
    "\n",
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = exkaldi.hmm.MonophoneHMM(lexicons=lexicons, name=\"mono\")\n",
    "\n",
    "model0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___model0___ is an Exkaldi __MonophoneHMM__ object. Exkaldi have monophone HMM-GMM and triphone HMM-GMM achivements. We will introduce the later in next tutorial steps.\n",
    "\n",
    "Now, this model is void and unavaliable. We must initialize it's archtecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.initialize(feat=feat, topoFile=topoFile)\n",
    "\n",
    "model0.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are about to train this model. We provide a high-level API, __model0.train(...)__ to train this model in a nutshell, but we still introduce the basic training step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train HMM-GMM in detail\n",
    "\n",
    "#### 1. Prepare the int-ID format transcription.\n",
    "\n",
    "We actually use the transcription with int-ID format, so we convert text format to int-ID format firstly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transFile = os.path.join(dataDir, \"train\", \"text\")\n",
    "oov = lexicons(\"oov\")\n",
    "\n",
    "trans = exkaldi.hmm.transcription_to_int(transFile, lexicons, oov)\n",
    "\n",
    "type(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___trans___ is an exkaldi __Transcription__ object, which is designed to hold the transcription. We save the int-format transcription for further using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intTransFile = os.path.join(dataDir, \"exp\", \"text.int\")\n",
    "\n",
    "trans.save(intTransFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look the transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compile the train graph.\n",
    "\n",
    "Compile the train graph. Here, L.fst file is necessary. In early step (3_prepare_lexicons), we have generated one, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L_disambig.fst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though decision tree is actually useless when traing monophone HMM-GMM, Kaldi still need it. \n",
    "\n",
    "When the monophone HMM is initialized, a temp tree is generated automatically. Use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model0.tree\n",
    "\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___tree___ is an exkaldi DecisionTree object. In next step, we will introduce how to build a normal decision tree. But now, skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_mono\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGraphFile = os.path.join(outDir, \"train_graph\")\n",
    "\n",
    "model0.compile_train_graph(tree=tree, transcription=trans, LFile=Lfile, outFile=trainGraphFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Align acoustic feature averagely in order to start the first train step.\n",
    "\n",
    "Kaldi align feature equally in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali = model0.align_equally(feat, trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ali___ is an exkaldi BytesAlignmentTrans object.\n",
    "\n",
    "You can covert it to numpy format to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali.subset(nHead=1).to_numpy(aliType=\"transitionID\", hmm=model0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use alignment to accumulate the statistics in order to update the parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsFile = os.path.join(outDir, \"stats.acc\")\n",
    "\n",
    "model0.accumulate_stats(feat=feat, alignment=ali, outFile=statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Use these statistics to update model parameters.\n",
    "\n",
    "This step can increase the numbers of gaussians. We try to use 10 more gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetGaussians = model0.info.gaussians + 10\n",
    "\n",
    "model0.update(statsFile, numgauss=targetGaussians)\n",
    "\n",
    "model0.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next training step, use Viterbi aligning to instead of average aligning.\n",
    "\n",
    "#### 6. Align acoustic feature with Vertibi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali = model0.align(feat=feat, trainGraphFile=trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali.subset(nHead=1).to_numpy(aliType=\"transitionID\", hmm=model0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we have a high-level API to train the model.\n",
    "\n",
    "### Train HMM-GMM with high-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(trainGraphFile)\n",
    "os.remove(statsFile)\n",
    "del ali\n",
    "del trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to train 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.train(feat, transFile, Lfile, tempDir=outDir, num_iters=10, max_iter_inc=8, totgauss=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model and alignment are saved in files automatically. You can save them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFile = os.path.join(outDir, \"0.mdl\")\n",
    "#model0.save(modelFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
